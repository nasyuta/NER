# Задача распознавания именованных сущностей в тексте (NER)

В рамках данного исследования в качестве объекта использован англоязычный датасет объемом 1 048 575 строк. Он содержит четыре столбца: Sentence, Word, POS (Part of Speech) и TAG. Набор данных предназначен для решения задач NER и размечен в формате BIO (Beginning, Inside, Outside).
Общий план выполнения работы включал следующие этапы:
- Анализ и изучение структуры данных;
- Предобработка данных;
- Обучение нейронной сети;
- Анализ полученных результатов.

Используемый датасет — Entity Annotated Corpus — представляет собой корпус англоязычных текстов, размеченных по типам сущностей. Каждый токен размечен тегом согласно формату BIO. В частности, используются следующие обозначения сущностей:
Geo — географический объект;
Org — организация;
Per — персона (человек);
Gpe — геополитическое образование;
Time — временные показатели;
Art — артефакт;
Eve — событие;
Nat — природное явление;
O — токены, не относящиеся к именованным сущностям.
Анализ распределения тегов показал, что подавляющее большинство слов помечены как O, то есть не являются сущностями. Примерно 85% слов не представляют интереса с точки зрения NER-задачи.

Для использования текстовой информации в нейронной сети необходимо преобразовать данные в числовой формат — векторизовать. Для этого были созданы словари:
token2idx и idx2token — сопоставляют токены и их числовые индексы;
tag2idx и idx2tag — сопоставляют теги и соответствующие индексы.
С помощью этих словарей осуществляется кодирование текста и меток в числовые векторы. После векторизации каждый токен и тег в датасете заменяется на соответствующее числовое значение.
Для подачи данных в модель нейронной сети важно, чтобы все последовательности имели одинаковую длину. Этого удалось достичь с помощью функции pad_sequences. После дополнения и нормализации данные были разделены на обучающую и тестовую выборки.

Для решения задачи NER была спроектирована и реализована модель на основе двунаправленной LSTM (Bi-LSTM) с дополнительным слоем LSTM.
Архитектура модели включает следующие ключевые компоненты:
Embedding слой, преобразующий токены в плотные векторные представления;
Bidirectional LSTM, учитывающий контекст как слева, так и справа от текущего слова;
LSTM слой, обрабатывающий последовательности слева направо;
TimeDistributed слой, обеспечивающий множественный выход для каждого токена.

В ходе выполнения работы была достигнута поставленная цель: разработка и обучение модели нейронной сети для извлечения именованных сущностей из текстов на английском языке.
Были решены следующие задачи:
Изучены теоретические основы задачи NER;
Подготовлен и векторизован исходный набор данных;
Построена и обучена модель на основе Bi-LSTM и LSTM;
Проведена оценка качества модели и экспериментальное сравнение параметров.
В результате было установлено:
Функция активации Softmax обеспечивает наилучшую точность;
Повышение количества эпох обучения и нейронов в скрытом слое способствует улучшению результатов;
Оптимальные параметры: 128 нейронов, 10 эпох, функция активации Softmax.
Таким образом, представленная модель может эффективно применяться для извлечения именованных сущностей, а также служить базой для дальнейших улучшений и исследований в области обработки естественного языка.
